{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**获取最新写法：** https://python.langchain.com/docs/versions/migrating_chains/map_reduce_chain/#legacy-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 需要同步jupyter运行异步事件循环\n",
    "nest_asyncio.apply()\n",
    "llm = ChatOpenAI(model_name=\"gpt-4\", temperature=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用 Playwright 抓取网页\n",
    "uv pip install playwright\n",
    "!playwright install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "async def async_load_playwright(url: str) -> str:\n",
    "    \"\"\"使用PlayWright加载指定的URL，并使用BeautifulSoup解析。\"\"\"\n",
    "    from bs4 import BeautifulSoup\n",
    "    from playwright.async_api import async_playwright\n",
    "\n",
    "    results = \"\"\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(headless=True)\n",
    "        try:\n",
    "            page = await browser.new_page()\n",
    "            await page.goto(url)\n",
    "\n",
    "            page_source = await page.content()\n",
    "            soup = BeautifulSoup(page_source, \"html.parser\")\n",
    "\n",
    "            for script in soup([\"script\", \"style\"]):\n",
    "                script.extract()\n",
    "\n",
    "            text = soup.get_text()\n",
    "            lines = (line.strip() for line in text.splitlines())\n",
    "            chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
    "            results = \"\\n\".join(chunk for chunk in chunks if chunk)\n",
    "        except Exception as e:\n",
    "            results = f\"错误：{e}\"\n",
    "        await browser.close()\n",
    "    return results\n",
    "\n",
    "\n",
    "def run_async(coro):\n",
    "    event_loop = asyncio.get_event_loop()\n",
    "    return event_loop.run_until_complete(coro)\n",
    "\n",
    "\n",
    "@tool\n",
    "def browse_web_page(url: str) -> str:\n",
    "    \"\"\"以详细的方式抓取整个网页。可能会导致解析问题。\"\"\"\n",
    "    return run_async(async_load_playwright(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "from langchain.base_language import BaseLanguageModel\n",
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.tools import BaseTool\n",
    "from pydantic import Field\n",
    "\n",
    "\n",
    "# 🧩 可选：分块函数\n",
    "def _get_text_splitter() -> RecursiveCharacterTextSplitter:\n",
    "    return RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=100,\n",
    "    )\n",
    "\n",
    "\n",
    "# 🧠 Tool 实现\n",
    "class WebpageQATool(BaseTool):\n",
    "    name: str = \"query_webpage\"\n",
    "    description: str = \"浏览网页并检索与问题相关的信息，并附带来源。\"\n",
    "\n",
    "    # 参数：模型、分块器、chain类型\n",
    "    llm: BaseLanguageModel\n",
    "    chain_type: Literal[\"stuff\", \"map_reduce\", \"refine\", \"map_rerank\"] = \"map_reduce\"\n",
    "    text_splitter: RecursiveCharacterTextSplitter = Field(default_factory=_get_text_splitter)\n",
    "\n",
    "    def _run(self, url: str, question: str) -> str:\n",
    "        \"\"\"使用 QA chain 回答网页内容中的问题，并返回答案和来源。\"\"\"\n",
    "\n",
    "        try:\n",
    "            # 👇 1. 抓网页内容（你需要实现这个函数）\n",
    "            html = browse_web_page.run(url)\n",
    "\n",
    "            # 👇 2. 封装为 Document + 切块\n",
    "            doc = Document(page_content=html, metadata={\"source\": url})\n",
    "            docs = self.text_splitter.split_documents([doc])\n",
    "\n",
    "            # 👇 3. 构建 QA Chain（含来源引用）\n",
    "            chain = load_qa_with_sources_chain(\n",
    "                llm=self.llm,\n",
    "                chain_type=self.chain_type,\n",
    "                verbose=False,\n",
    "            )\n",
    "\n",
    "            # 👇 4. 运行 QA chain\n",
    "            result = chain({\"input_documents\": docs, \"question\": question}, return_only_outputs=True)\n",
    "\n",
    "            # 👇 5. 返回格式化结果\n",
    "            answer = result.get(\"answer\", \"\")\n",
    "            sources = result.get(\"sources\", \"\")\n",
    "            return f\"回答：{answer}\\n\\n来源：{sources}\"\n",
    "\n",
    "        except Exception as e:\n",
    "            return f\"❌ 处理失败：{str(e)}\"\n",
    "\n",
    "    async def _arun(self, url: str, question: str) -> str:\n",
    "        raise NotImplementedError(\"异步暂未实现。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_website_tool = WebpageQATool(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.qa_with_sources.retrieval import RetrievalQAWithSourcesChain\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores.faiss import FAISS\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 1. 加载网页（支持 JS 动态加载的页面除外）\n",
    "url = \"https://en.wikipedia.org/wiki/OpenAI\"\n",
    "loader = WebBaseLoader([url])\n",
    "docs = loader.load()  # 返回的是 List[Document]\n",
    "\n",
    "# 2. 分块（必须步骤，保证适配 LLM 输入限制）\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "split_docs = splitter.split_documents(docs)\n",
    "\n",
    "# 3. 构建向量索引\n",
    "vectorstore = FAISS.from_documents(split_docs, OpenAIEmbeddings())\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# 4. 构建 RetrievalQAWithSourcesChain\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "qa_chain = RetrievalQAWithSourcesChain.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    chain_type=\"stuff\",  # 可改为 map_reduce/refine/map_rerank\n",
    "    return_source_documents=True,  # 可选：返回完整文档\n",
    ")\n",
    "\n",
    "# 5. 提问\n",
    "question = \"OpenAI 是做什么的？\"\n",
    "result = qa_chain.invoke({\"question\": question})\n",
    "\n",
    "# 6. 输出结果\n",
    "print(\"🧠 答案：\", result[\"answer\"])\n",
    "print(\"📎 来源：\", result[\"sources\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 封装成工具\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryWebpageWithSourcesTool(BaseTool):\n",
    "    name: str = \"query_webpage\"\n",
    "    description: str = \"读取网页并回答问题，附带来源\"\n",
    "\n",
    "    llm: BaseLanguageModel\n",
    "\n",
    "    def _run(self, url: str, question: str) -> str:\n",
    "        docs = WebBaseLoader(url).load()\n",
    "        split_docs = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100).split_documents(docs)\n",
    "        vectorstore = FAISS.from_documents(split_docs, OpenAIEmbeddings())\n",
    "        retriever = vectorstore.as_retriever()\n",
    "\n",
    "        qa_chain = RetrievalQAWithSourcesChain.from_chain_type(\n",
    "            llm=self.llm, retriever=retriever, return_source_documents=False\n",
    "        )\n",
    "\n",
    "        result = qa_chain.invoke({\"question\": question})\n",
    "        return f\"🧠 回答：{result['answer']}\\n📎 来源：{result['sources']}\"\n",
    "\n",
    "    async def _arun(self, url: str, question: str):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "好的，下面是**增强版的网页问答工具 `QueryWebpagesWithSourcesTool`**，具备以下功能：\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ 功能亮点：\n",
    "\n",
    "| 功能                | 描述                                            |\n",
    "| ----------------- | --------------------------------------------- |\n",
    "| 🔗 支持多个网页链接       | 多网页合并提问，一次问多个网页内容                             |\n",
    "| 📄 自动网页解析         | 用 `WebBaseLoader` 抓网页正文                       |\n",
    "| 🧩 文本分块 + 嵌入 + 检索 | 自动构建向量数据库                                     |\n",
    "| 🧠 支持多种 QA 模式     | `stuff`, `map_reduce`, `refine`, `map_rerank` |\n",
    "| 📎 来源引用           | 输出中包含提取的网页链接（source）                          |\n",
    "| 🧱 可接入 Agent      | 完整 Tool 结构，支持 Tool Calling                    |\n",
    "| ⚙️ 可返回结构化 JSON    | 答案 + sources 可直接处理                            |\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ 完整代码（多网页问答工具）\n",
    "\n",
    "```python\n",
    "from typing import List, Union, Literal\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.tools import BaseTool\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores.faiss import FAISS\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain.schema import Document\n",
    "from langchain.base_language import BaseLanguageModel\n",
    "\n",
    "\n",
    "# 🧠 参数结构：用于 Tool 接收 inputs\n",
    "class WebQAInput(BaseModel):\n",
    "    urls: Union[str, List[str]] = Field(..., description=\"要提问的网页链接，可以是一个或多个\")\n",
    "    question: str = Field(..., description=\"要提问的问题\")\n",
    "\n",
    "\n",
    "# 🛠️ Tool 实现\n",
    "class QueryWebpagesWithSourcesTool(BaseTool):\n",
    "    name: str = \"query_webpages_with_sources\"\n",
    "    description: str = \"读取一个或多个网页并回答问题，附带引用来源\"\n",
    "\n",
    "    llm: BaseLanguageModel\n",
    "    chain_type: Literal[\"stuff\", \"map_reduce\", \"refine\", \"map_rerank\"] = \"map_reduce\"\n",
    "    chunk_size: int = 1000\n",
    "    chunk_overlap: int = 100\n",
    "\n",
    "    args_schema = WebQAInput\n",
    "\n",
    "    def _run(self, urls: Union[str, List[str]], question: str) -> str:\n",
    "        try:\n",
    "            # 支持字符串或列表\n",
    "            url_list = [urls] if isinstance(urls, str) else urls\n",
    "\n",
    "            # Step 1: 加载网页\n",
    "            docs: List[Document] = []\n",
    "            for url in url_list:\n",
    "                web_docs = WebBaseLoader(url).load()\n",
    "                for d in web_docs:\n",
    "                    d.metadata[\"source\"] = url  # 明确来源\n",
    "                docs.extend(web_docs)\n",
    "\n",
    "            # Step 2: 分块\n",
    "            splitter = RecursiveCharacterTextSplitter(\n",
    "                chunk_size=self.chunk_size, chunk_overlap=self.chunk_overlap\n",
    "            )\n",
    "            split_docs = splitter.split_documents(docs)\n",
    "\n",
    "            # Step 3: 向量索引\n",
    "            vectorstore = FAISS.from_documents(split_docs, OpenAIEmbeddings())\n",
    "            retriever = vectorstore.as_retriever()\n",
    "\n",
    "            # Step 4: QA Chain\n",
    "            qa_chain = RetrievalQAWithSourcesChain.from_chain_type(\n",
    "                llm=self.llm,\n",
    "                retriever=retriever,\n",
    "                chain_type=self.chain_type,\n",
    "                return_source_documents=False\n",
    "            )\n",
    "\n",
    "            result = qa_chain.invoke({\"question\": question})\n",
    "            answer = result.get(\"answer\", \"\")\n",
    "            sources = result.get(\"sources\", \"\")\n",
    "\n",
    "            return f\"🧠 回答：{answer}\\n📎 来源：{sources}\"\n",
    "\n",
    "        except Exception as e:\n",
    "            return f\"❌ 出错：{str(e)}\"\n",
    "\n",
    "    async def _arun(self, urls: Union[str, List[str]], question: str) -> str:\n",
    "        raise NotImplementedError(\"暂不支持异步运行\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ 示例使用方式：\n",
    "\n",
    "```python\n",
    "tool = QueryWebpagesWithSourcesTool(\n",
    "    llm=ChatOpenAI(temperature=0),\n",
    "    chain_type=\"map_rerank\"\n",
    ")\n",
    "\n",
    "output = tool.run({\n",
    "    \"urls\": [\n",
    "        \"https://en.wikipedia.org/wiki/OpenAI\",\n",
    "        \"https://en.wikipedia.org/wiki/ChatGPT\"\n",
    "    ],\n",
    "    \"question\": \"OpenAI 和 ChatGPT 有什么关系？\"\n",
    "})\n",
    "\n",
    "print(output)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ 示例输出：\n",
    "\n",
    "```\n",
    "🧠 回答：OpenAI 是 ChatGPT 的开发者。ChatGPT 是由 OpenAI 开发的大型语言模型应用。\n",
    "📎 来源：https://en.wikipedia.org/wiki/OpenAI, https://en.wikipedia.org/wiki/ChatGPT\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ 扩展建议（可选）：\n",
    "\n",
    "| 扩展          | 建议做法                                          |\n",
    "| ----------- | --------------------------------------------- |\n",
    "| 支持 JSON 输出  | 改成 `return {\"answer\": ..., \"sources\": ...}`   |\n",
    "| 支持 Agent 调用 | 设置 `tool.description` 和 `args_schema`         |\n",
    "| 异步抓网页       | 用 `aiohttp + asyncio.gather` 替代 WebBaseLoader |\n",
    "| 增加日志        | `print(f\"Loaded from {url}\")` 等调试辅助           |\n",
    "\n",
    "---\n",
    "\n",
    "## 🧩 小贴士：如果网页 JS 渲染怎么办？\n",
    "\n",
    "`WebBaseLoader` 不能抓动态 JS 内容，你可以替换为：\n",
    "\n",
    "```python\n",
    "from langchain_community.document_loaders import PlaywrightURLLoader\n",
    "\n",
    "loader = PlaywrightURLLoader(urls=[...], headless=True)\n",
    "docs = loader.load()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "是否需要我为你补充这段代码的 Tool Calling JSON schema（OpenAI functions/assistant API 用）？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "好的！你想要的“网页问答工具”进一步扩展成**支持多轮对话**的能力，即：\n",
    "\n",
    "> **记住之前的问题与答案，上下文连贯地对话问网页内容**\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ 核心思路\n",
    "\n",
    "在原有的网页问答基础上，**加入聊天历史的记忆机制**：\n",
    "\n",
    "1. 维护一份多轮 `chat_history`（对话上下文）\n",
    "2. 在每次提问时，把过去的问答也一并输入模型\n",
    "3. 保证答案连贯、上下文相关\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ 使用组件说明\n",
    "\n",
    "| 组件                             | 用法                        |\n",
    "| ------------------------------ | ------------------------- |\n",
    "| `ConversationalRetrievalChain` | 官方推荐链，支持历史对话记忆            |\n",
    "| `chat_history`                 | 传入 `(user, ai)` 对列表，构成上下文 |\n",
    "| `Retriever`                    | 使用向量检索构建（从网页文本构建）         |\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ 完整多轮对话版 Web QA Tool\n",
    "\n",
    "```python\n",
    "from typing import List, Tuple, Union, Literal\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.tools import BaseTool\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores.faiss import FAISS\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.schema import Document\n",
    "from langchain.base_language import BaseLanguageModel\n",
    "\n",
    "\n",
    "class ConversationalWebQAInput(BaseModel):\n",
    "    urls: Union[str, List[str]] = Field(..., description=\"网页链接（单个或多个）\")\n",
    "    question: str = Field(..., description=\"当前用户提问\")\n",
    "    history: List[Tuple[str, str]] = Field(default_factory=list, description=\"对话历史，格式为[(user, ai), ...]\")\n",
    "\n",
    "\n",
    "class ConversationalWebQATool(BaseTool):\n",
    "    name: str = \"conversational_web_qa\"\n",
    "    description: str = \"读取网页并进行多轮对话问答，支持上下文记忆和来源引用\"\n",
    "\n",
    "    llm: BaseLanguageModel\n",
    "    chunk_size: int = 1000\n",
    "    chunk_overlap: int = 100\n",
    "\n",
    "    args_schema = ConversationalWebQAInput\n",
    "\n",
    "    def _run(self, urls: Union[str, List[str]], question: str, history: List[Tuple[str, str]]) -> str:\n",
    "        try:\n",
    "            url_list = [urls] if isinstance(urls, str) else urls\n",
    "\n",
    "            # Step 1: 加载网页\n",
    "            docs: List[Document] = []\n",
    "            for url in url_list:\n",
    "                web_docs = WebBaseLoader(url).load()\n",
    "                for d in web_docs:\n",
    "                    d.metadata[\"source\"] = url\n",
    "                docs.extend(web_docs)\n",
    "\n",
    "            # Step 2: 文本切块\n",
    "            splitter = RecursiveCharacterTextSplitter(chunk_size=self.chunk_size, chunk_overlap=self.chunk_overlap)\n",
    "            split_docs = splitter.split_documents(docs)\n",
    "\n",
    "            # Step 3: 向量索引\n",
    "            vectorstore = FAISS.from_documents(split_docs, OpenAIEmbeddings())\n",
    "            retriever = vectorstore.as_retriever()\n",
    "\n",
    "            # Step 4: 构建 Conversational QA Chain\n",
    "            qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "                llm=self.llm,\n",
    "                retriever=retriever,\n",
    "                return_source_documents=True\n",
    "            )\n",
    "\n",
    "            # Step 5: 多轮对话\n",
    "            result = qa_chain.invoke({\"question\": question, \"chat_history\": history})\n",
    "\n",
    "            # Step 6: 输出答案与来源\n",
    "            answer = result[\"answer\"]\n",
    "            sources = \", \".join({doc.metadata.get(\"source\", \"未知\") for doc in result[\"source_documents\"]})\n",
    "\n",
    "            return f\"🧠 回答：{answer}\\n📎 来源：{sources}\"\n",
    "\n",
    "        except Exception as e:\n",
    "            return f\"❌ 出错：{str(e)}\"\n",
    "\n",
    "    async def _arun(self, *args, **kwargs):\n",
    "        raise NotImplementedError(\"暂不支持异步\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ 使用示例（模拟多轮对话）\n",
    "\n",
    "```python\n",
    "tool = ConversationalWebQATool(llm=ChatOpenAI(temperature=0))\n",
    "\n",
    "history = []\n",
    "\n",
    "q1 = \"OpenAI 是做什么的？\"\n",
    "a1 = tool.run({\"urls\": \"https://en.wikipedia.org/wiki/OpenAI\", \"question\": q1, \"history\": history})\n",
    "print(a1)\n",
    "history.append((q1, a1))\n",
    "\n",
    "q2 = \"他们的著名产品有哪些？\"\n",
    "a2 = tool.run({\"urls\": \"https://en.wikipedia.org/wiki/OpenAI\", \"question\": q2, \"history\": history})\n",
    "print(a2)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ 示例输出（可上下文连贯）\n",
    "\n",
    "```\n",
    "🧠 回答：OpenAI 是一家从事人工智能研究的实验室。\n",
    "📎 来源：https://en.wikipedia.org/wiki/OpenAI\n",
    "\n",
    "🧠 回答：他们的著名产品包括 ChatGPT、Codex 和 DALL·E。\n",
    "📎 来源：https://en.wikipedia.org/wiki/OpenAI\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ 整体结构图\n",
    "\n",
    "```\n",
    "User Question + Chat History\n",
    "        ↓\n",
    " ConversationalRetrievalChain\n",
    "        ↓\n",
    "Retriever (网页向量库)\n",
    "        ↓\n",
    "回答 + 来源\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ 总结\n",
    "\n",
    "| 功能                     | 是否支持                    |\n",
    "| ---------------------- | ----------------------- |\n",
    "| 多网页合并问答                | ✅                       |\n",
    "| 上下文记忆                  | ✅（通过 `chat_history`）    |\n",
    "| 多轮提问连贯                 | ✅                       |\n",
    "| 引用来源网页                 | ✅                       |\n",
    "| 支持 Agent / ToolCalling | ✅（符合 LangChain Tool 接口） |\n",
    "\n",
    "---\n",
    "\n",
    "是否需要我再扩展为支持**LangGraph 状态机式多轮问答**，或者接入 LangChain Expression Language？如果你想让它接入真实 Web Agent，我也可以帮你封装。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import batched\n",
    "from typing import Literal\n",
    "\n",
    "import faiss\n",
    "import rich\n",
    "from langchain.base_language import BaseLanguageModel\n",
    "from langchain.chains.qa_with_sources.retrieval import RetrievalQAWithSourcesChain\n",
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.tools import BaseTool\n",
    "from langchain.vectorstores.faiss import FAISS\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from pydantic import BaseModel, Field\n",
    "from rich.console import Console\n",
    "from rich.markdown import Markdown\n",
    "\n",
    "from app.core import settings\n",
    "\n",
    "\n",
    "# 🧠 参数结构：用于 Tool 接收 inputs\n",
    "class WebQAInput(BaseModel):\n",
    "    urls: str | list[str] = Field(..., description=\"要提问的网页链接，可以是一个或多个\")\n",
    "    question: str = Field(..., description=\"要提问的问题\")\n",
    "\n",
    "\n",
    "# 🛠️ Tool 实现\n",
    "class QueryWebpagesWithSourcesTool(BaseTool):\n",
    "    name: str = \"query_webpages_with_sources\"\n",
    "    description: str = \"读取一个或多个网页并回答问题，附带引用来源\"\n",
    "\n",
    "    llm: BaseLanguageModel\n",
    "    chain_type: Literal[\"stuff\", \"map_reduce\", \"refine\", \"map_rerank\"] = \"map_reduce\"\n",
    "    chunk_size: int = 1000\n",
    "    chunk_overlap: int = 100\n",
    "\n",
    "    args_schema: type[BaseModel] = WebQAInput\n",
    "\n",
    "    def _run(self, urls: str | list[str], question: str) -> str:\n",
    "        try:\n",
    "            # 支持字符串或列表\n",
    "            url_list = [urls] if isinstance(urls, str) else urls\n",
    "\n",
    "            # Step 1: 加载网页\n",
    "            docs: list[Document] = []\n",
    "            for url in url_list:\n",
    "                web_docs = WebBaseLoader(url).load()\n",
    "                for d in web_docs:\n",
    "                    d.metadata[\"source\"] = url  # 明确来源\n",
    "                docs.extend(web_docs)\n",
    "\n",
    "            # Step 2: 分块\n",
    "            splitter = RecursiveCharacterTextSplitter(chunk_size=self.chunk_size, chunk_overlap=self.chunk_overlap)\n",
    "            split_docs = splitter.split_documents(docs)\n",
    "\n",
    "            # Step 3: 向量索引\n",
    "            embeddings = OpenAIEmbeddings(\n",
    "                model=\"Qwen/Qwen3-Embedding-8B\",\n",
    "                openai_api_key=settings.SILICONFLOW_API_KEY,\n",
    "                openai_api_base=settings.SILICONFLOW_API_BASE,\n",
    "            )\n",
    "            index = faiss.IndexFlatL2(len(embeddings.embed_query(\"hello world\")))\n",
    "\n",
    "            vector_store = FAISS(\n",
    "                embedding_function=embeddings,\n",
    "                index=index,\n",
    "                docstore=InMemoryDocstore(),\n",
    "                index_to_docstore_id={},\n",
    "            )\n",
    "            for batch in batched(split_docs, 64):\n",
    "                vector_store.add_documents(batch)\n",
    "            retriever = vector_store.as_retriever()\n",
    "\n",
    "            # Step 4: QA Chain\n",
    "            qa_chain = RetrievalQAWithSourcesChain.from_chain_type(\n",
    "                llm=self.llm,\n",
    "                retriever=retriever,\n",
    "                chain_type=self.chain_type,\n",
    "                return_source_documents=True,\n",
    "            )\n",
    "\n",
    "            result = qa_chain.invoke({\"question\": question})\n",
    "            answer = result.get(\"answer\", \"\")\n",
    "            sources = result.get(\"sources\", \"\")\n",
    "\n",
    "            # 调试信息：打印 result 的键\n",
    "            print(f\"调试：result 包含的键: {list(result.keys())}\")\n",
    "            print(f\"调试：原始 sources: '{sources}'\")\n",
    "\n",
    "            # 多种方式提取 sources\n",
    "            source_urls = set()\n",
    "\n",
    "            # 方法1：从 source_documents 中提取\n",
    "            if \"source_documents\" in result and result[\"source_documents\"]:\n",
    "                for doc in result[\"source_documents\"]:\n",
    "                    if hasattr(doc, \"metadata\") and \"source\" in doc.metadata:\n",
    "                        source_urls.add(doc.metadata[\"source\"])\n",
    "                        print(f\"调试：从 source_documents 提取到: {doc.metadata['source']}\")\n",
    "\n",
    "            # 方法2：如果 sources 字段不为空，解析它\n",
    "            if sources and sources.strip():\n",
    "                # sources 可能是逗号分隔的字符串\n",
    "                parsed_sources = [s.strip() for s in sources.split(\",\") if s.strip()]\n",
    "                source_urls.update(parsed_sources)\n",
    "                print(f\"调试：从 sources 字段解析到: {parsed_sources}\")\n",
    "\n",
    "            # 方法3：如果还是没有找到，使用原始 URL\n",
    "            if not source_urls:\n",
    "                source_urls.update(url_list)\n",
    "                print(f\"调试：使用原始 URL: {url_list}\")\n",
    "\n",
    "            final_sources = \", \".join(source_urls) if source_urls else \"未找到来源\"\n",
    "            print(f\"调试：最终 sources: '{final_sources}'\")\n",
    "\n",
    "            return f\"🧠 回答：{answer}\\n📎 来源：{final_sources}\"\n",
    "\n",
    "        except Exception as e:\n",
    "            return f\"❌ 出错：{str(e)}\"\n",
    "\n",
    "    async def _arun(self, urls: str | list[str], question: str) -> str:\n",
    "        raise NotImplementedError(\"暂不支持异步运行\")\n",
    "\n",
    "\n",
    "tool = QueryWebpagesWithSourcesTool(\n",
    "    llm=ChatOpenAI(\n",
    "        model=\"Qwen/Qwen3-32B\",\n",
    "        api_key=settings.SILICONFLOW_API_KEY,\n",
    "        base_url=settings.SILICONFLOW_API_BASE,\n",
    "        temperature=0.8,\n",
    "    ),\n",
    "    chain_type=\"map_reduce\",  # 改为 stuff 模式，对 sources 返回更稳定\n",
    ")\n",
    "\n",
    "output = tool.run(\n",
    "    {\n",
    "        \"urls\": [\"https://en.wikipedia.org/wiki/OpenAI\", \"https://en.wikipedia.org/wiki/ChatGPT\"],\n",
    "        \"question\": \"OpenAI 和 ChatGPT 有什么关系？\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# rich.print(output)\n",
    "# rich渲染成 markdown 打印\n",
    "console = Console()\n",
    "console.print(Markdown(output))\n",
    "# \"\"\"🔧 如果你想定制它\n",
    "# 你可以替换其中任意组件：\n",
    "# 替换 retriever（如换成 MultiVectorRetriever, SelfQueryRetriever）\n",
    "# 自定义 prompt\n",
    "# 使用 ChatPromptTemplate + StructuredOutputParser 控制结构化输出\n",
    "# 替换 chain_type 逻辑为更强的 LangGraph 状态机\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试修复后的工具\n",
    "print(\"=== 测试修复后的工具 ===\")\n",
    "output = tool.run(\n",
    "    {\n",
    "        \"urls\": [\"https://en.wikipedia.org/wiki/OpenAI\", \"https://en.wikipedia.org/wiki/ChatGPT\"],\n",
    "        \"question\": \"OpenAI 和 ChatGPT 有什么关系？\",\n",
    "    }\n",
    ")\n",
    "\n",
    "rich.print(output)\n",
    "\n",
    "# 如果还是没有 sources，尝试单个 URL 测试\n",
    "print(\"\\n=== 单个 URL 测试 ===\")\n",
    "output_single = tool.run({\"urls\": \"https://en.wikipedia.org/wiki/OpenAI\", \"question\": \"OpenAI 是什么时候成立的？\"})\n",
    "\n",
    "rich.print(output_single)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
