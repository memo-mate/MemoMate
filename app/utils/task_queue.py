import logging

import orjson
import rich
import tenacity
from kafka import KafkaConsumer, KafkaProducer
from kafka.structs import TopicPartition

from app.core.config import settings
from app.core.log_adapter import logger
from app.enums.queue import QueueTopic


def get_topic_lag(topic: QueueTopic, groups: list[str]) -> int:
    """è·å–Topicçš„Lag"""
    if not groups:
        # å¦‚æœæœªæŒ‡å®šæ¶ˆè´¹è€…ç»„ï¼Œåˆ™è¿”å›0
        logger.warning("æœªæŒ‡å®šæ¶ˆè´¹è€…ç»„ï¼Œæ— æ³•è®¡ç®—æ»åé‡")
        return 0

    total_lag = 0
    try:
        # åˆ›å»ºæ¶ˆè´¹è€…æ¥è·å–ä¸»é¢˜çš„åˆ†åŒºä¿¡æ¯
        consumer = KafkaConsumer(bootstrap_servers=settings.KAFKA_BOOTSTRAP_SERVERS)

        # è·å–ä¸»é¢˜çš„åˆ†åŒº
        partitions = consumer.partitions_for_topic(topic)
        if not partitions:
            logger.warning(f"ä¸»é¢˜ {topic} ä¸å­˜åœ¨æˆ–æ²¡æœ‰åˆ†åŒº")
            return 0

        # ä¸ºæ¯ä¸ªåˆ†åŒºåˆ›å»ºTopicPartitionå¯¹è±¡
        topic_partitions = [TopicPartition(topic=topic, partition=p) for p in partitions]

        # è·å–æ¯ä¸ªåˆ†åŒºçš„å¼€å§‹å’Œç»“æŸåç§»é‡
        beginning_offsets = consumer.beginning_offsets(topic_partitions)  # æœ€æ—©å¯ç”¨åç§»é‡
        end_offsets = consumer.end_offsets(topic_partitions)  # æœ€æ–°åç§»é‡

        # å¯¹æ¯ä¸ªæ¶ˆè´¹è€…ç»„è¿›è¡Œè®¡ç®—
        for group in groups:
            # åˆ›å»ºæ¶ˆè´¹è€…æ¥è·å–ç‰¹å®šç»„çš„åç§»é‡
            group_consumer = KafkaConsumer(
                bootstrap_servers=settings.KAFKA_BOOTSTRAP_SERVERS, group_id=group, request_timeout_ms=30000
            )

            # è·å–æ¶ˆè´¹è€…ç»„å½“å‰çš„åç§»é‡
            committed_offsets = {}
            group_exists = True

            try:
                # å°è¯•è·å–å·²æäº¤çš„åç§»é‡
                for tp in topic_partitions:
                    offset = group_consumer.committed(tp)
                    committed_offsets[tp] = offset if offset is not None else beginning_offsets[tp]
            except Exception as e:
                # å¦‚æœå‡ºé”™ï¼ˆä¾‹å¦‚æ¶ˆè´¹è€…ç»„ä¸å­˜åœ¨ï¼‰ï¼Œåˆ™å‡è®¾æ¶ˆè´¹è€…ç»„ä»æœªæ¶ˆè´¹è¿‡ä»»ä½•æ¶ˆæ¯
                logger.warning(f"æ— æ³•è·å–æ¶ˆè´¹è€…ç»„ {group} çš„æäº¤åç§»é‡ï¼Œå‡è®¾ä»æœªæ¶ˆè´¹", group=group, exc_info=e)
                group_exists = False
                for tp in topic_partitions:
                    committed_offsets[tp] = beginning_offsets[tp]  # ä½¿ç”¨æœ€æ—©çš„åç§»é‡

            # è®¡ç®—æ¯ä¸ªåˆ†åŒºçš„lagå¹¶æ±‚å’Œ
            group_lag = 0
            for tp in topic_partitions:
                lag = end_offsets[tp] - committed_offsets[tp]
                group_lag += lag
                logger.debug(f"åˆ†åŒº {tp.partition} çš„æ»åé‡: {lag}", partition=tp.partition, lag=lag, group=group)

            # å¦‚æœæ¶ˆè´¹è€…ç»„ä¸å­˜åœ¨ï¼Œæ·»åŠ æç¤ºä¿¡æ¯
            if not group_exists:
                logger.info(
                    f"æ¶ˆè´¹è€…ç»„ {group} å¯èƒ½ä¸å­˜åœ¨æˆ–æœªæ›¾è¿æ¥ï¼Œæ€»æ»åé‡: {group_lag}",
                    group=group,
                    total_lag=group_lag,
                )

            total_lag += group_lag
            group_consumer.close()

    except Exception as e:
        logger.exception("è®¡ç®—ä¸»é¢˜æ»åé‡æ—¶å‡ºé”™", topic=topic, exc_info=e)
    finally:
        consumer.close()

    return total_lag


def get_topic_lag_by_group(topic: QueueTopic, group: str) -> int:
    """è·å–æŒ‡å®šæ¶ˆè´¹è€…ç»„çš„æ»åé‡"""
    return get_topic_lag(topic, [group])


@tenacity.retry(stop=tenacity.stop_after_attempt(3), wait=tenacity.wait_exponential(multiplier=1, min=4, max=15))
def send_message_to_topic(topic: QueueTopic, message: dict) -> None:
    """å‘é€æ¶ˆæ¯åˆ°æŒ‡å®šä¸»é¢˜"""
    producer = KafkaProducer(
        bootstrap_servers=settings.KAFKA_BOOTSTRAP_SERVERS,
        value_serializer=lambda x: orjson.dumps(x),
    )
    producer.send(topic, message)


if __name__ == "__main__":
    logging.basicConfig(level=logging.DEBUG)
    rich.print(f"ğŸš€ [red]æ»åé‡: {get_topic_lag('foobar', ['test'])}[/red]")
